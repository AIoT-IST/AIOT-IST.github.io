[
{
	"uri": "https://aiot-ist.github.io/mcm-204/",
	"title": "MCM-204",
	"tags": [],
	"description": "",
	"content": "ADLINK IST Connected Factory MCM-204 Discover how to use the MCM-204 and find the releated questions.\n"
},
{
	"uri": "https://aiot-ist.github.io/eos-iseries/",
	"title": "EOS-iSeries",
	"tags": [],
	"description": "",
	"content": "ADLINK IST Connected Factory EOS-iSeries Discover how to use the EOS-iSeries and find the releated questions.\n"
},
{
	"uri": "https://aiot-ist.github.io/eos-iseries/gettingstart/",
	"title": "Getting start with Yolov3",
	"tags": [],
	"description": "",
	"content": "This tutorial will guide you how to getting start with EOS-iSeries from un-boxing.\nStep 1: Hardware wiring  Connect the peripherals, keyboard, mouse, monitor and cameras. Connect 110V AC power source to the terminal block Power on   Step 2: Run inference with different source The path of inference sample locates on the C:\\Users\\user\\Desktop\\ADLINK. You can select image, video, webcam or Basler GigE camera as inference source.\nOpen Terminal and paste commands below:\n Image  cd C:\\Users\\user\\Desktop\\adlink\\darknet-For_basler_camera\\build\\darknet\\x64 yolo_console_dll.exe data/coco.names yolov3.cfg yolov3.weights C:\\Users\\user\\Desktop\\ADLINK\\darknet-For_basler_camera\\data\\dog.jpg    Terminate program by close the Terminal or ctrl+c.\n   Video\ncd C:\\Users\\user\\Desktop\\adlink\\darknet-For_basler_camera\\build\\darknet\\x64 yolo_console_dll.exe data/coco.names yolov3.cfg yolov3.weights test.mp4      Webcam\ncd C:\\Users\\user\\Desktop\\adlink\\darknet-For_basler_camera\\build\\darknet\\x64 yolo_console_dll.exe web_camera      Basler GigE camera\n   Open pylon Viewer and make sure GigE camera works. Key in commands cd C:\\Users\\user\\Desktop\\adlink\\darknet-For_basler_camera\\build\\darknet\\x64 yolo_console_dll.exe basler_camera or Click Run_basler_camera_with_Object_Detection.bat in folder      "
},
{
	"uri": "https://aiot-ist.github.io/eos-iseries/faq/",
	"title": "FAQ",
	"tags": [],
	"description": "",
	"content": "Frequently asked questions (FAQ) about Pylon\nHow to grab the Image from the GigE Basler.   Step1 : Set the Lan port IP address ? Assign the TCP/IP4 IP to be 192.168.11.1  Step2: How to set the Camera IP by Pylon? Set the Ip 192.168.11.4 by Pylon IP configurator.   Video   "
},
{
	"uri": "https://aiot-ist.github.io/dex/dexpro/newloadproject/",
	"title": "00-New project &amp; Run Script &amp; combine Script",
	"tags": [],
	"description": "",
	"content": " How to create a new project Reload a project(blf) when remodifying  How to combine a script before running Run the script (.SPT) What is the difference between with SPT VS BLF  How to create a new project Step:  1 Click New 2 Click Select 3 Choice the folder for save the script data 4 Click Ok  Reload a project when remodifying Step  1 Click load 2 Choice the .blf list file  How to combine a script before running Step  1 Click mouse button of right in any one getting.bmp 2 Combine Script -\u0026gt; General (It\u0026rsquo;s ok for choicing any one bmp) 3 Inupt the name and click ok  Run the script Step  1 Click load 2 Choice the .spt list file 3 select the file 4 Click open   Click Run Scripts  What is the difference between with SPT VS BLF Pleas see below list\n"
},
{
	"uri": "https://aiot-ist.github.io/dex/quicklystart/",
	"title": "00-Quckly start (Video)",
	"tags": [],
	"description": "",
	"content": "DEX-100 Quckly start (video) Follow those videos you can quickly finish one project by yourself.  You can check other links for getting more tips, samples, and notes.\n -製作圖層篇,How to make the layer\n-設定Page ID篇,How to set the PageID\n-編輯腳本篇,How to edit the instruction\n-OCR使用REST上拋資料篇,How to get the OCR by restful\n-設定OP Screen篇,How to set the OP Screen\n-自動執行腳本篇,How to set for autorun the script\n-OCR設定篇,How to add the OCR\n-OCR 字庫訓練工具篇,How to train OCR to improve accuracy\n"
},
{
	"uri": "https://aiot-ist.github.io/dex/dexpro/instruction/goto/",
	"title": "01-Jump",
	"tags": [],
	"description": "",
	"content": " Use GoTo fulfill JUMP function Use both element of GoTo with Lebel fulfill JUMP function  Use PageID fulfill JUMP function Use both element of PageID with Lebel fulfill JUMP function Use Table Compare fulfill JUMP function  How to design \u0026ldquo;Jump function\u0026rdquo; by GOTO \u0026amp; PageIdentify \u0026amp; label \u0026amp; Table compare. There are three function can fulfill JUMP\n GOTO : Directly jump to other command line. PageID : It is like the pattern match and jump to other command line. Compare Table : Compare the OCR Table and jump to other command line.  Use GoTo fulfill JUMP function Discription Use both element of GoTo with Lebel fulfill JUMP function Discription Use PageID fulfill JUMP function Discription Use both element of PageID with Lebel fulfill JUMP function Discription Use Table Compare fulfill JUMP function Discription "
},
{
	"uri": "https://aiot-ist.github.io/dex/dexpro/layer/",
	"title": "01-Layer",
	"tags": [],
	"description": "",
	"content": "How to add the bmp(layer) and select the folder for project You can flow the below steps or watch the video link.\n Quickly guide Video  SOP  Select one folder to save the script data.  Click Connect  Select the browser of Remote Control  Click Control   Move mouse or key the keyboard to you want page(bmp)\n  Click snapshot\n  "
},
{
	"uri": "https://aiot-ist.github.io/dex/unboxing/",
	"title": "01-Unboxing",
	"tags": [],
	"description": "",
	"content": "DEX-100 Unboxing  Equipment wiring map  DEX-100 wiring for VGA  DEX-100 wiring for DVI DEX-100 wiring for USB DEX-100 wiring for PS2  DEX-100 for editing environment What is the different between (DP to VAG) and (VGA out) ?  Equipment wiring map The basic wiring is below the figure. DEX-100 wiring for VGA  This is PC connected to screen by VGA cable.  Separate the VGA cable that the VGA-INPUT connects to dex-100 then VGA-OUTPUT connects to screen.   DEX-100 wiring for DVI  This is PC connected to screen by DVI cable.  Separate the DVI cable that the DVI -INPUT connects to dex-100 then DVI -OUTPUT connects to screen. 1.DVI-D is dual-link type please referring.\n 2.DVI Output shall display when DVI input and DVI output are connected then restart the dex-100.\n   DEX-100-wiring-usb  These are USB of keyboard and mouse how to wire with DEX.   DEX-100-wiring-ps2  These are PS2 of keyboard and mouse how to wire with DEX.   DEX-100 for editing environment  The dex-100 has one GUI that is dex-pro, the dex-pro can design a script for auto-running and show the exclusive screen by DP. Due to editing the script that requires ones pair keyboard and mouse then show in the exclusive screen.   What is the different between (DP to VAG) and (VGA out) ?  Describe the different functions between (PD to VAG) and (VGA OUT), Please referring the below figure. e  "
},
{
	"uri": "https://aiot-ist.github.io/dex/dexpro/addscript/",
	"title": "02-Add script",
	"tags": [],
	"description": "",
	"content": " Choice the bmp which you want to design Click mouse button of left side then Add the Script Select the instruction   How to add script Choice the bmp which you want to design Click mouse button of left side then Add the Script Select the instruction "
},
{
	"uri": "https://aiot-ist.github.io/dex/dexpro/instruction/mouse/",
	"title": "02-Mouse",
	"tags": [],
	"description": "",
	"content": " Click Dclick Up Down Coordinate refer from OCR Table  How to Click、Dclick the mouse in the script Instruction can simulat those command for mouse button of left,middle and right.\nFollow the steps:\n1. Choice the getting_xxx.bmp 2. Screen capture mode 3. Use mouse click the bmp in right side 4. Show the coordinate X and Y 5. Can add bye hotkey or add-Script 6. You can see the click/Dclick instruction in the script How to shift the popup form in instruction       Follow the steps:\n1. Click the Starting poistion 2. Recorder the coordinate X \u0026amp; Y. 3. Choice the instruction of \u0026ldquo;left click down\u0026rdquo; and keyin the coordinate X \u0026amp; Y. 4. Click the second poistion 5. Recorder the coordinate X \u0026amp; Y. 6. Choice the instruction of \u0026ldquo;move\u0026rdquo; and keyin the coordinate X \u0026amp; Y. 7. Click the ended poistion 8. Recorder the coordinate X \u0026amp; Y. 9. hoice the instruction of \u0026ldquo;left click up\u0026rdquo; and keyin the coordinate X \u0026amp; Y. How the position coordinate refer the dynamic OCR Table   sample data\n Script.7z restful.py SOP.zip  "
},
{
	"uri": "https://aiot-ist.github.io/dex/dexpro/instruction/keyin/",
	"title": "03-Keyin",
	"tags": [],
	"description": "",
	"content": " From Text From OCR Table From external txt Choice Number key  From Text The instrction can key in the statice string.\nFollow the steps:\n Choice the getting_xxx.bmp Screen capture mode Add script and select instruction of key-in  Key-in from Text x = 1 from text Text = \u0026ldquo;ADLINK GOGO\u0026rdquo;   From OCR Table   Choice the getting_xxx.bmp\n  Screen capture mode\n  Add script and select instruction of key-in   Key-in from Text\n   x = 3 from text Y = 1 OCR Table PS: Key-in value from the \u0026ldquo;OCR Table 1 = ABCD1234 \u0026quot;\n  From external txt   Choice the getting_xxx.bmp\n  Screen capture mode\n  Add script and select instruction of key-in   Key-in from external text   Choice Number key Keyboard\u0026rsquo;s 0 to 9 there are two types for sent the different ASCII, so one parameter can switch it. "
},
{
	"uri": "https://aiot-ist.github.io/dex/dexpro/pageid/",
	"title": "03-PageID",
	"tags": [],
	"description": "",
	"content": "How to identify the feature for each bmp(layer) You can flow the below steps or watch the link below Video.\n Quickly guide Video  SOP  Open you desing\u0026rsquo;s [.blf] file.  Select the page of Page Identfy Define and draw the region(ROI)  Example The ROI all parameter values of pixel size must be multiples 4.\n Save config the region of the feature(ROI) after adjust the threshold for each bmp(layer).  The larger threshold can tolerate more noise however it shall loss prcision.\n Click ok  Load config for checking PageIdentify enabled  Click the button of connect again then seeing the Light blue bar, It is successful.  "
},
{
	"uri": "https://aiot-ist.github.io/dex/dexpro/instruction/",
	"title": "04-Instruction",
	"tags": [],
	"description": "",
	"content": "Overview Video Video Funtions list How to design \u0026ldquo;Jump function\u0026rdquo;  jump to flag or next step by goto Jump to flag when this page is right. Jump to next or previous step when comparing the OCR table.  How to design \u0026ldquo;click function\u0026rdquo;  Left-button,right-button and midel-button all can single-click and double-click. Left-button,right-button and midel-button all can click-down or click-up. The mouse can click multi-point by dynamically update the OCR table.  How to design \u0026ldquo;key-in function\u0026rdquo;  key-in string is fixed. key-in string is from OCR Table. key-in string is from text.  Add OCR and save the log  How add OCR in script How to add the Exist ROI setting How to save the OCR table in CSV  How to design a for loop  Use the single loop. use the dual loop.  "
},
{
	"uri": "https://aiot-ist.github.io/dex/dexpro/instruction/ocrandlog/",
	"title": "04-OCR and Log",
	"tags": [],
	"description": "",
	"content": " How to add the ROI for OCR in script How to set the \u0026ldquo;Exsit Setting\u0026rdquo;  Gaussian blur Threashold Super resolution Interpolation Confidence   How to save the ROI result in csv  Enable the sharing OCR Table items Add instruction for recoding the organizations in CSV  Save all OCR or part of OCR      How to add the ROI for OCR in script Follow the steps:\n1. Choice the getting_xxx.bmp 2. Screen capture mode 3. Use mouse drawing the ROI in the layer before click add  Draw the ROI which you want to monitor. (1~4) Click the Add for increasing the OCR instruciton in the script.(5)   4. Select the \u0026ldquo;Exist Settings\u0026rdquo; with each ROI Base on the amount of your designed ROI and select the \u0026ldquo;Exist ROI Setting\u0026rdquo; until lastly ROI. There are 4 pair instructions in the script after adding OCR. (For this demo )\nIf your \u0026ldquo;Exist Setting\u0026rdquo; is such as the left side of the below figure , pls view the link\n How to set the Exist Setting Introduc the parameters in Exist Setting.\nAdd new one \u0026ldquo;Exist Settings\u0026rdquo; recipe    Gaussian blur Functional difference for real case\nThreashold Super resolution Interpolation White and Black List Traineddata and Configuration What is the \u0026ldquo;Traineddata\u0026rdquo;?\nDue to character have many font,size and color, We usually separate the same feature in the same trainedata folder. If you don\u0026rsquo;t have any ideal,Please referring the Link\nWhat is the \u0026ldquo;Configuration\u0026rdquo;?\nChoose the configuration (single selection) selection). Press the Advanced Setting button for Tesseract advanced settings if required as follow. For the more parameters information in detail , you have to refer the tesseract from google. config.cfg is the golden and config1.cfg is up to user defined)\nConfidence How to save the ROI result in csv The script can log that you want to monitor OCR in CSV after enable sharing the OCR Table.\nEnable the sharing OCR Table items:    Open the configuration managment    Click the DDS \u0026amp; REST (OCR configuration)     Select Reest    Modify 0 to 20 and check yes then click \u0026ldquo;Save to items\u0026rdquo; (for this sample)      Check thes OCR item to be Ture that you want to monitor.      Stop REST    Run REST (Reset the REST module)      It is successful when you resee the restful module popup again.      Exit     Add instruction for recoding the organizations in CSV    Open you desing\u0026rsquo;s [.blf] file.      Choice the bmp which you want to design      Click mouse button of left side then Add the Script    Save all OCR or part of OCR Select \u0026ldquo;MSG_SAVE_TABLE_TO\u0026rdquo; instruction (save all OCR)   Select \u0026ldquo;MSG_SAVE_TABLE_TO\u0026rdquo; instruction (part of OCR)   where is the CSV ? There is a file per day.\n  Path C:\\Users\\USER\\Documents\\RCM_TABLE_LOG The system default keeps the files for 30 days however you can modify the parameter.\n "
},
{
	"uri": "https://aiot-ist.github.io/dex/dexpro/instruction/loop/",
	"title": "05-LOOP",
	"tags": [],
	"description": "",
	"content": " How to use the loop  How to use both loop2 with loop  How to the loop X: Loop in execution.\n 0: go to previous steps; =0: go to the last instruction \u0026lt;0: go to next steps\n Y: Loop is ended.\n 0: go to next steps =0: go to the last instruction \u0026lt;0: go to previous steps;\n W: This value denotes the iteration times of the loop\n Pleas referring the sample:   How to use both loop2 with loop They are a pair both loop2 and loop when you use the double loop.\n Pleas referring the sample: The loop2\u0026rsquo;s start instruction must be the first loop.   "
},
{
	"uri": "https://aiot-ist.github.io/dex/dexpro/instruction/pageidetify/",
	"title": "06-PageIdentify",
	"tags": [],
	"description": "",
	"content": " How to use the PageIdentify  How to the use the PAgeIdentify Introduction the parameter X: number of instructions to jump  X\u0026gt;0: go to previous steps X=0: go to the last instruction X\u0026lt;0: go to next steps  Y: jump mode.  0: jump by instruction number 1: jump by label  W: target page id  Referring the number of bmp   Pleas referring the sample 1: The pattern matches(Yes) then going to the \u0026ldquo;Jump\u0026rdquo; label.\nThe pattern doesn\u0026rsquo;t match(No) then go to the next step.\nPleas referring the sample 2: The pattern matches(Yes) then going to the next 4 steps.\nThe pattern doesn\u0026rsquo;t match(No) then go to the next step.\n"
},
{
	"uri": "https://aiot-ist.github.io/dex/dexpro/instruction/restful/",
	"title": "07-Restful",
	"tags": [],
	"description": "",
	"content": " How to add the instruction for RESTFUL API Upload all items once Uplaod one by one RESTFUL function list RESTFUL sample code  How to add the instruction for RESTFUL API Sop 0. Please enable the OCR Table you can refer the Enable the sharing OCR Table items,if you don\u0026rsquo;t how to set. 1. Add the script 2. Select the MSG_SAVE_TABLE_TO_LOG Upload all items once  Q : 0,Upload all once through RESTFUL(Submachinestatus) X : 0,Save all items    Text : Bypass the parameter when X is 0 and recode the ROI Table referring to the items of True status   Get the all items by Submachinestatus of RESTFUL API.\n  The items auto upload once based on your design OCR amount when executing this instruciton.   There are 4 ROI case.\nThere are 9 ROI case\nUpload one by one  Q : 1,Upload one bye one through RESTFUL X : 1,Save selected items Text : 1~4;7    (This case is only allowed those 1 to 4 and 7 of OCR table Set or Get by RESTFUL API.)   You can see the relationship in the below image.\nWhat is one by one The RESTFUL\u0026rsquo;s Get function can get one data once for you select OCR table items and without parsing anything metadata.\nThe RESTFUL\u0026rsquo;s Set function can set one data to OCR table for handshaking with other app.\n1.Set the data to OCR table by anytime.\n2.Get the current data from OCR table after executing this command.\n3.It wait more time by more you select OCR items.\n RESTFUL function list They support two format both XML and Json. Doc\n1. SubmachineStatuse  You can get all the OCR tables that you design for sharing,but mabye you shall analyze it by yourself.  2. Get   You can get one metadata from OCR Table that you design for sharing.\n  Those OCR TABLE are update after executing this MSG_SAVE_TABLE_TO_LOG instrution.\n  The 0 in the OCR table cannot be obtained\n 3. Set  You can set any data to OCR Table.  4. Executescript  It can trigg the script that you want to autorun.  5. Stopscript  It can stop the current script.  RESTFUL Sample code  C# sample Python sample  "
},
{
	"uri": "https://aiot-ist.github.io/dex/video/video-source/",
	"title": "1 - Choice the Dex-100 Video Source",
	"tags": [],
	"description": "",
	"content": "Choice the Dex-100 Video Source Click the Frame Grabber Setting and choice the Source input.  Dex-Pro -\u0026gt; Tools -\u0026gt; Config -\u0026gt; Fram Grabber Setting  Use the Diag.exe for checking the current video information.  Path -\u0026gt; -\u0026gt; C:\\Program Files\\ADLINK\\DEX-100\\utility\\Diag.exe  Clear horizontal and vertical offset values  Click the button of \u0026quot;Frame Adjust\u0026quot;   Please set 0 for all the offset\n  Select source and resolution  Select source from VGA or DVI   Select resolution \u0026ldquo;Auto\u0026rdquo;  Get the Video informations   Check the both result for Resolution and Signal, if the connection is successful.\n  If doesn\u0026rsquo;t detected the signal, follow the steps for troubleshooting.    Check the Local machine setting for display resolution.    Reconnect the local machine VGA cable to monitor.    Reboot the local machine.    Check the resolution from the monitor.    Reconnect the VGA to Dex-100.    Check Frame Grabber Setting whether the auto mode is selected for any resolution.    "
},
{
	"uri": "https://aiot-ist.github.io/dex/video/video-quality/",
	"title": "2 - Video quality adjustment",
	"tags": [],
	"description": "",
	"content": "How to adjust quality when inputting the bad video  3. Using the Diag.exe 4. Select source \u0026amp; resolution 5. Draw the image by clicking the \u0026ldquo;Start\u0026rdquo; 6. Confirm the current image that is right 7. Using the \u0026ldquo;Video Quality Analysis\u0026rdquo; 8. Choose the test interval and start the testing 9. Cancel the testing log or save it in storage 10. System auto full in the result in the parameter of the sampling phas 11. Trobleshooting  Steps 1 Boot up the dex-100 Power on the DEX-100\n2 Input the Video source (VGA or DVI) Plug-in the video source cable.\n3 Using the Diag  Path -\u0026gt; C:\\Program Files\\ADLINK\\DEX-100\\utility\\Diag.exe  4 Select source and resolution  Select source  Select resolution   5 Draw the image by clicking the button of Start You shall see the result when grabbing is successful.\n     It is the current source    It is the current resolution    It is succeful or filed    If the resolution can\u0026rsquo;t match your choose resolution or the signal can\u0026rsquo;t be detected , please follow the below steps.\n  Dex-Pro -\u0026gt; Tools -\u0026gt; Config -\u0026gt; Fram Grabber Setting     6 Confirm the current image that is right   It is not right, please retrying Step 2~5 again.\nDex-100 can\u0026rsquo;t process some Intel chips that can\u0026rsquo;t output your required resolution, because the resolution always keeps in one resolution.\n   7 Using the Video Quality Analysis   Test VGA video quality for a long time and give suggested parameters\n  (Ensure that the video quality of the machine is almost the same throughout the day.)\n    8 Choose the test interval and start the testing Choose the test interval There are several parameters for your requirement.\n Click the \u0026ldquo;start\u0026rdquo; button.   9 Cancel the testing log or save it in storage You shall see the report after automatically test the video quality.\n Click the ok button.  10 System auto full in the result in the parameter of the sampling phas It is successful when you see the value be set in \u0026ldquo;Sampling Phase\u0026rdquo; from the testing result.\nThe system only brings into the testing result of the sampling phase in the right parameter.\n    11 Trobleshooting   If you get the large value from \u0026ldquo;Average Dynamic Noise\u0026rdquo;, we suggest you that replace the VGA cable with anti-noise (EMI CORES) when getting the bad value after using Video Quality Analysis.\n    "
},
{
	"uri": "https://aiot-ist.github.io/dex/video/resolution/",
	"title": "3 - Create new resolution",
	"tags": [],
	"description": "",
	"content": "How to increase a new resolution  Frame Grabber Setting  Attachments   Frame Grabber Setting  Path -\u0026gt; DEX-Pro -\u0026gt; Tool -\u0026gt; Config -\u0026gt; Frame Grabber Setting    Selecte Auto mode in \u0026ldquo;Frame Grabbe Configuration\u0026rdquo;\n    Steps () 1 Get the new resolution by Screen.    2 Run the ADLINK_SFDT Run the ADLINK_SFDT.exe follow the below path.\n Path -\u0026gt; C:\\Program Files\\ADLINK\\DEX-100\\utility\\ADLINK_SFDT     3 Detect the parameters from the current video You can get the parameters from the current resolution after clicking the “Sense ”button.\n   If no parameters are displayed, please refer to the below link (troubleshooting)\n video-source\n4 Backup the dex100_rgb.txt Clone the dex100.rgb to desktop and copy one more to be a backup file.\n Path -\u0026gt; C:\\Windows\\dex100_rgb.txt     5 Increase a new resolution table  Please search for a set of resolution closest to what you desire and copy it to the top of the \u0026ldquo;dex100_rgb.txt\u0026rdquo;.\n    6 Edit the resolution name [Width Height fps Interlace]  Name the new title and modify the parameters (Width、Height 、FPS) for easily selected the resolution list.\n    7 Fill in the parameters [HF VF VTotal Vsw]  Fill in the parameters from ADLINK_SFDT tool in “dex100_rgb.txt”\n    8 Get the unknown parameters  Get the unknown parameters by filling in the new resolution((Width、Height 、FPS) in the first sheet “CVT” of VesaCVT.xlsx\n    9 Fill in the parameters to Way_2 Fill in the parameters from the ADLINK_SFD in the sheet of Way_2.\n   10 Fill in the parameters [Hf HTotal Hsv Hbp Vf VTotal Vsw Vbp PClock Cr] Please key-in each color-bound box parameter to dex100_rgb.\n   11 Fill in the parameters in content of the new resolution set Please key-in each color-bound box parameter to dex100_rgb.\n   12 Save the txt 13 Replace the dex100_rgb.txt Replace the new dex100_rgb.txt to this C:\\Windows\\dex100_rgb.txt.\n14 Reboot the Dex-100 15 Reuse the Diag.exe  Path -\u0026gt; C:\\Program Files\\ADLINK\\DEX-100\\utility\\Diag.exe  15 Checking the resolution table can be choiced.    16 Choice the new list and click the button on start    17 Align the screen edge by button of Frame Adjust    Attachments VesaCVT.xlsx\ndex100_rgb.txt\n"
},
{
	"uri": "https://aiot-ist.github.io/dex/mouse/ps2metadata/",
	"title": "Detect the PS2 metadata",
	"tags": [],
	"description": "",
	"content": "How to acquit the ps2 metadata for KB or Mouse.  Step1: Power off both Dex-100 \u0026amp; host-machine Step2: Boot up the Dex-100 and run the Dbgview as administrator  Step3: Enable the function to follow the below image Step4: Setting the diffrent filter-string Step5: Power on the host-machine Step6: Record the logs by Dbgview  Step7: Save the log  Troubleshooting for DebugView DebugView download  Power off both of Dex-100 and host-machine The Dex-100 choices the USB or PS2 protocol by both keyboard and mouse successful connection with host-machine, but the handshake is beginning when power on for PS2 mode.\nBoot up the Dex-100 and run the Dbgview as administrator Enable the function to follow the below image DEX-100-wiring-usb Setting the diffrent filter-string Key-in the different filter-string for collecting the data of the mouse or keyboard and click ok.\n  For log keyboard matamata : KBD\n  For log Mouse matamata : KVM2\n  You can click the button and choose each string for collecting the data of the mouse or keyboard.\n Power on the host-machine Dex-100 choices the PS2 mode when hand-shake is successful both with the PS2 mouse and host-machine after power on the host-machine.\nDex-100 has only one rule for choosing PS2 or USB protocol by detecting the ps2 mouse.\n Record the logs by Dbgview You can see some metadata to show on the Debug Print , if it is successful.\nIt recordes logs when moving mouse or key-in any keyboard.\nPlease record both of Bypass mode \u0026amp; control mode.\n Save the log Save the log and sent back for Adlink contact window.\nTroubleshooting for DebugView Please follow the troubleshooting when you see the warning message\n Remove the Dbgv.sys as administrator or renmae it. Path : C:\\Windows\\System32\\drivers\n  Retry step1 to step7.  Attachment DebugView(save as to your computer)\n"
},
{
	"uri": "https://aiot-ist.github.io/dex/mouse/disablemouseaccelerator/",
	"title": "Disable Mouse accelerator",
	"tags": [],
	"description": "",
	"content": "How to turn off the Mouse accelerator?  Step0: Disable Mouse accelerator by UI  Step1: Run the Registry Editor Step2: Change the Mouse speed setting  Disable Mouse accelerator by UI Wake up the Mouse Properties and disable the \u0026ldquo;Enhance pointer precision\u0026rdquo;\nPath:Control Panel\\All Control Panel Items\\Mouse\n Please follow the next step if you can\u0026rsquo;t find the UI of Mouse properties.\nRun the registry editor Using the hot-ky \u0026ldquo;Win+R\u0026rdquo;\nWake up the Registry Editor\nChange the mouse speed setting Edite the Mouse speed setting from 1 to 0. Define 1 = Enable 0 = Disabl\nPath:HKEY_CURRENT_USER\\Control Panel\\Mouse\\MouseSpeed\n "
},
{
	"uri": "https://aiot-ist.github.io/euresys/",
	"title": "Euresys",
	"tags": [],
	"description": "",
	"content": "ADLINK IST Connected Factory Euresys Tutorials about Easy Tool series\n"
},
{
	"uri": "https://aiot-ist.github.io/euresys/easycolor/",
	"title": "EasyColor",
	"tags": [],
	"description": "",
	"content": "This tutorial will guide you how to getting start EasyColor by Euresys\n  Performing Thresholding on Color Images\n  Performing Color Segmentation\n  Performing Thresholding on Color Images Following this tutorial, you will learn how to use EasyColor to segment a color source image, by setting a threshold value for each color component of the current color system. For example, to retrieve the solder pads on a PCB, you\u0026rsquo;ll perform a color segmentation based on the golden pixels (H), with a loose discrimination on the brightness (L) and saturation (S), to eliminate surface and lighting effects.\n   Load the source image Create a destination image Create a color lookup table Perform the color segmentation Link on line Doc        Performing Color Segmentation Following this tutorial, you will learn how to use EasyImage to perform color segmentation.   Load the source image Create a color lookup table Perform the color segmentation Link on line Doc      "
},
{
	"uri": "https://aiot-ist.github.io/euresys/easydeeplearning/",
	"title": "EasyDeepLearning",
	"tags": [],
	"description": "",
	"content": "This tutorial will guide you how to getting start DeepLearning by Euresys\n  Performing EasyClassify\n  Performing EasySegment\n  Performing EasyClassify    Open the Deep Learning Studio Choice the Classifier Mode  Import whole lab images of Good \u0026amp; broken \u0026amp; defective. Training the data Testing the inference Link on line Doc        Performing EasySegment    Open the Deep Learning Studio Choice the Unsupervised Mode  Import whole folders of Good \u0026amp; NG Training the data Adjust the parameters Testing the inference Link on line Doc      "
},
{
	"uri": "https://aiot-ist.github.io/euresys/easyfind/",
	"title": "EasyFind",
	"tags": [],
	"description": "",
	"content": "This tutorial will guide you how to getting start EasyFind by Euresys\n  Detecting Highly-Degraded Occurrences of a Reference Model in Multiple Files\n  Improving the Score of Found Instances by Using \u0026ldquo;Don\u0026rsquo;t Care Areas\u0026rdquo;\n  Detecting Highly-Degraded Occurrences of a Reference Model in Multiple Files Following this tutorial, you will learn how to use EasyFind to detect in multiple images highly-degraded occurrences of a reference model. The degradation can be due to noise, blur, occlusion, missing parts or unstable illumination conditions.\n   Load the reference image Create an ROI to define the reference model on the reference image Learn the reference model Set rotation and scaling tolerances Select multiple images Browse multiple images Link on line Doc        Improving the Score of Found Instances by Using Do Not Care Areas Following this tutorial, you will learn how to use EasyFind to handle \u0026ldquo;don\u0026rsquo;t care areas\u0026rdquo; in geometric pattern matching. \u0026ldquo;Don\u0026rsquo;t care areas\u0026rdquo; help to define in the image the meaningful features only, by masking the areas that might change from image to image, such as text and numbers.   Loading the reference image Creating an ROI to define the reference model on the reference image Learning the reference model Setting a rotation tolerance Detecting instances of the reference model without \u0026ldquo;don\u0026rsquo;t care areas\u0026rdquo; Defining the \u0026ldquo;don\u0026rsquo;t care area\u0026rdquo; Detecting instances of the reference model with \u0026ldquo;don\u0026rsquo;t care areas\u0026rdquo; Link on line Doc      "
},
{
	"uri": "https://aiot-ist.github.io/euresys/easyfind/qa/",
	"title": "EasyFind (Q&amp;A)",
	"tags": [],
	"description": "",
	"content": "Q\u0026amp;A list   How to reduce the working time for EPatternFinder.Find processing time\n  How to reduce the working time for EPatternFinder.Find processing time   Description the scenario:   Users would like to reduce the working time or give up the execution when having a high processing time.\n  Fundamental for EasyFinder   EasyFind works internally in 2 stages.\n It selects reasonable candidates for the pattern It makes a finer analysis/positioning of the candidates.    Suggestion way   There is a new parameter that may help by using the number of selected candidates has a direct impact on the processing time. Link on line Doc\n"
},
{
	"uri": "https://aiot-ist.github.io/euresys/easygauge/",
	"title": "EasyGauge",
	"tags": [],
	"description": "",
	"content": "This tutorial will guide you how to getting start EasyFind by Euresys\n  Measuring the Rotation Angle of an Object\n  Measuring the Diameter of a Circle\n  Measuring a Distorted Rectangle\n  Locating Points Regarding to a Coordinate System\n  Unwarping a Distorted Image\n  Measuring the Rotation Angle of an Object Following this tutorial, you will learn how to use EasyGauge to measure the rotation angle of a CCD sensor package. As we only need to retrieve an angle value, it\u0026rsquo;s not required to work in a calibrated field of view. All geometrical parameters and results will be express as numbers of pixels.\n   Load the source image Attach a line gauge to the image Perform the inspection Link on line Doc        Measuring the Diameter of a Circle Following this tutorial, you will learn how to use EasyGauge to measure the diameter of a circle in an image.   Load the calibration image Calibrate the field of view Load the source image Attach a circle gauge to the image Perform the inspection Link on line Doc        Measuring a Distorted Rectangle Following this tutorial, you will learn how to use EasyGauge to perform measurements on a distorted rectangle component..   Load the calibration image Calibrate the field of view Load the distorted image Attach a rectangle gauge to the image Perform the inspection Link on line Doc        Locating Points Regarding to a Coordinate System Following this tutorial, you will learn how to use EasyGauge to perform lead frames inspection. This operation determines the dimension, position, curvature, size, angle or diameter of the lead frames with an excellent accuracy. Robustness is ensured by powerful edge-point selection mechanisms that are intuitive and easy to tune, allowing measurement in cluttered images.   Load the calibration image Calibrate the field of view Loading a lead frame image Setting a coordinate system Attaching a point gauge to the frame shape Attaching other point gauges to the frame shape Loading another lead frame image Tuning the coordinate system Performing the inspection Link on line Doc        Unwarping a Distorted Image Following this tutorial, you will learn how to use EasyGauge to perform grid calibration, and unwarp a distorted image.   Load the calibration image Calibrate the field of view Load the distorted image Unwarp the distorted image Link on line Doc      "
},
{
	"uri": "https://aiot-ist.github.io/euresys/easyimage/",
	"title": "EasyImage",
	"tags": [],
	"description": "",
	"content": "This tutorial will guide you how to getting start EasyImage by Euresys\n Transforming a Gray-Level image into its Black and White Edges Extracting an Object Contour Detecting the Corners of an Object Using Harris Corner Detector Detecting a Horizontal or Vertical Line Using Projection Creating a Flexible Mask \u0026amp; Computing Gray-Level Statistics Using a Flexible Mask Detecting the Corners of an Object Using Hit-and-Miss Transform Extracting a Vector Using Profile Function Enhancing an X-ray image Correcting Non-Uniform Illumination Correcting Shear Effect Correcting Skew Effect  Video   Function_1 Thresholding Following this tutorial, you will learn how to use EasyImage to convert a gray-level source image into a binary destination image. Thresholding an image transforms all the gray pixels into black or white pixels, depending on whether they are below or above a specified threshold. Thresholding an image makes further analysis easier.   How to use the singal threshold How to use the dual-threshold How to use the Adaptive Threshold Link on line Doc        Function_2 Extracting an Object Contour Following this tutorial, you will learn how to use EasyImage to trace an object outline in a gray-level image. The contour extraction allows you to get in a path vector all the points that constitute an object contour, just by clicking an edge of this object.   Load the source image Set the destination vector Extract the contour Link on line Doc        Function_3 Detecting the Corners by Using Harris Corner Detector Following this tutorial, you will learn how to use EasyImage to detect the corners of an object. The detection uses the Harris corner detector algorithm.   Load the source image Set the hit-and-miss kernel Apply the hit-and-miss transform Link on line Doc        Function_4 Detecting a Horizontal or Vertical Line Using Projection Following this tutorial, you will learn how to use EasyImage to detect defects (horizontal/vertical line) in a gray-level image.   Load the source image Set the destination vector Detect the defects Link on line Doc        Function_5 Computing Gray-Level Statistics Using a Flexible Mask Following this tutorial, you will learn how to compute gray-level statistics on an arbitrary-shaped area only.   Load the source image Invert the image Threshold the image Save the flexible maskLink on line Doc Load the flexible mask image Apply the flexible mask on the source image Compute the gray-level statisticsLink on line Doc        Function_6 Detecting the Corners of an Object Using Hit-and-Miss Transform Following this tutorial, you will learn how to use EasyImage to detect top corners in an image, using the hit-and-miss transform.   Load the source image Set the hit-and-miss kernel Apply the hit-and-miss transformLink on line Doc        Function_7 Extracting a Vector Using Profile Function Following this tutorial, you will learn how to use EasyImage to detect scratches.   Load the source image Set the destination vector and detecting the scratchesLink on line Doc        Enhancing an X-ray image Following this tutorial, you will learn how to use EasyImage to enhance an X-ray image.   Load the source image Set the convolution parameterLink on line Doc        Correcting Non-Uniform Illumination Following this tutorial, you will learn how to use EasyImage to correct non-uniform illumination in an image.   Load the source image Load the reference image Perform the correctionLink on line Doc        Correcting Shear Effect Following this tutorial, you will learn how to use EasyImage to correct a shear effect in an image. The following image is taken by a line-scan camera. The camera sensor was misaligned, resulting in a so-called shear effect.   Load the source image Create a destination image Set the pivots parameters Link on line Doc        Correcting Skew Effect Following this tutorial, you will learn how to use EasyImage to correct skew effect in an image.   Load the source image Creating a destination image Setting the correction angle Link on line Doc      "
},
{
	"uri": "https://aiot-ist.github.io/euresys/easymatch/",
	"title": "EasyMatch",
	"tags": [],
	"description": "",
	"content": "This tutorial will guide you how to getting start EasyMatch by Euresys\n  Learning a Pattern According to an ROI\n  Improving the Score of Matching Instances by Using \u0026ldquo;Don\u0026rsquo;t Care Areas\u0026rdquo;\n  Learning a Pattern According to an ROI Following this tutorial, you will learn how to use EasyMatch to learn a model from an ROI in a source image, and to perform pattern matching on the same image.\n   Load the source image Define an ROI Learn a model from the ROI Match the pattern Link on line Doc        Improving the Score of Matching Instances by Using Do Not Care Areas Following this tutorial, you will learn how to use EasyMatch to handle \u0026ldquo;don\u0026rsquo;t care areas\u0026rdquo;. \u0026ldquo;Don\u0026rsquo;t care areas\u0026rdquo; help to define in the image the meaningful features only, by masking the areas that might change from image to image.   Load the source image Learn the reference model Detect instances of the reference model without \u0026ldquo;don\u0026rsquo;t care areas\u0026rdquo; Define the \u0026ldquo;don\u0026rsquo;t care area\u0026rdquo; Detect instances of the reference model with \u0026ldquo;don\u0026rsquo;t care areas\u0026rdquo; Link on line Doc      "
},
{
	"uri": "https://aiot-ist.github.io/euresys/easyobject/",
	"title": "EasyObject",
	"tags": [],
	"description": "",
	"content": "This tutorial will guide you how to getting start EasyObject by Euresys\n  Removing Non-Significant Objects After Image Segmentation\n  Detecting Differences Between Images Using Min-Max References\n  Detecting Printing Errors Using a Flexible Mask\n  Removing Non-Significant Objects After Image Segmentation   Following this tutorial, you will learn how to use EasyObject to detect bad rice grains (largely dark) among many normal rice grains (largely light).\n Load the source image Perform image segmentation Remove the smallest objects Remove the smallest objects Link on line Doc        Detecting Differences Between Images Using Min-Max References Following this tutorial, you will learn how to use EasyObject to compare images. In this example, we will check the quality of a PCB film.   Load the source image Build min and max reference images Load an image to be inspected Compare the image with the reference images Link on line Doc        Detecting Printing Errors Using a Flexible Mask Following this tutorial, you will learn how to use a flexible mask to target and search specific areas in the image.   Load the source image Load the flexible mask image Inspect the image Link on line Doc      "
},
{
	"uri": "https://aiot-ist.github.io/euresys/parameters/",
	"title": "Parameters",
	"tags": [],
	"description": "",
	"content": " Color Lookup  Color Lookup IndexBits, the number of table entries and the corresponding table size are given below: Here are grouped images of those full RGB palettes by 4 bits \u0026amp; 5 bits \u0026amp; 6 bits.\n 4 bits = 12-bit RGB   5 bits = 15-bit RGB   6 bits = 18-bit RGB  Reference https://en.wikipedia.org/wiki/List_of_monochrome_and_RGB_color_formats#4-bit_grayscale_2\n"
},
{
	"uri": "https://aiot-ist.github.io/dex/video/",
	"title": "02-Video Source",
	"tags": [],
	"description": "",
	"content": "ADLINK IST Connected Factory Video Source There are some know how for sharing.\n"
},
{
	"uri": "https://aiot-ist.github.io/dex/mouse/",
	"title": "03-Mouse",
	"tags": [],
	"description": "",
	"content": "ADLINK IST Connected Factory Mouse There are several note for sharing.\n"
},
{
	"uri": "https://aiot-ist.github.io/dex/dexpro/",
	"title": "04-Dex-pro",
	"tags": [],
	"description": "",
	"content": "How to add the bmp(layer) and select the folder for project. How to use classic functions in the script.\n"
},
{
	"uri": "https://aiot-ist.github.io/dex/faq/",
	"title": "10-FAQ",
	"tags": [],
	"description": "",
	"content": "FAQ List  Specifications of DI1 DI2 LED Batch kill dex-pro The mouse follows offset How to restart the MSMQ How to check why the dexpro can\u0026rsquo;t grab the video How to check the exception-event How to backup or restore the traineddata to other machines How to quckly select TesseractDB for mutil-ROI  Specifications of DI1 DI2 Hardware Figure DI connector pin assignment DI1/2 function LED There are 3 LEDs in the hardware that can light by script command. kill the dex-pro by batch  Please run the cmd as administrator\n input the command taskkill /f /im DEX-Pro.exe\n The mouse follows offset  Check the machine PC’s mouse setting, Keep middle speed and disable “Enhance pointer precision”. If the offset distance is not fixed, adjust mouse speed of the machine PC   How to restart the MSMQ If the Dex-por can\u0026rsquo;t work by MSMQ, Please follow the below steps for Troubleshooting\n Go to \u0026ldquo;control panel\u0026rdquo;  Go to \u0026ldquo;Program\u0026rdquo;  Go to \u0026ldquo;Turn Windows Features on or off\u0026rdquo;  Disable the \u0026ldquo;Microsoft Message Queue(MSMQ) Server\u0026rdquo;  Reboot the DEX-100 Enable the \u0026ldquo;Microsoft Message Queue(MSMQ) Server\u0026rdquo;   How to check the setting when the dexpro can not grab the video If the Dex-pro can\u0026rsquo;t grab the video, We have several suggestions please follow checking the below steps.\n Please checking the setting is Auto by the dex-pro tool of Fram Grabber Configuration.  Please open the Diagnostic tool. Tool-Path \u0026quot;C:\\Program Files\\ADLINK\\DEX-100\\utility\u0026quot;   You shall see both the result for Resolution and Signal if the connection is successful.  If is no signal , please use below steps to help you troubleshooting.   A. Check the Local machine setting for display resolution. B. Reconnect the local machine VGA cable to monitor. C. Reboot the local machine. D. Check the resolution from the monitor. E. Reconnect the VGA to Dex-100 F. Check Frame Grabber Setting whether the auto mode is selected for any resolution.  How to check the exception-event You can track the Event Viewer if dex-pro encounters the Unexpected crashing.\n 1. Enter CMD (Command Prompt) 2. Key-in \u0026quot;eventvwr\u0026quot;  Path : \u0026quot;Event Viewer ==\u0026gt; Windows Logs ==\u0026gt; System\u0026quot; How to backup or restore the traineddata to other machines  A. Tools-\u0026gt;Config-\u0026gt;Tesseract OCR Setting-\u0026gt;Model and Config Management   B. Bakcup    Select all Export     Click Yes Select the folder ==\u0026gt; OK    C. Restore    Select all import (select the Folder name)     Select the folder ==\u0026gt; Ok   How to quckly select TesseractDB for mutil-ROI  A. In the blf mode   B. Select an image layer that has many ROI for OCR. C. Tools-\u0026gt;Config-\u0026gt;Tesseract OCR Setting-\u0026gt;Model and Config Management   D. Can be selected in batches and edit the ROI setting.   E. Click the Replace   F. Exit without change   G. Save Script   H. Recombine the script  "
},
{
	"uri": "https://aiot-ist.github.io/dex/sdkfwversion/",
	"title": "11-SDK &amp; FW Version &amp; Manual",
	"tags": [],
	"description": "",
	"content": "SDK Internal version : 1.2.5 2021/07/14\nOffical version : V5\n  SDK V5 (Download)\n  Release note\nHow to install SOP\n   Uninstall    Reboot    Install V5    Reboot    FW  FW-C5 (Download) FW-C7 (Download)\n   revision_history\nHow to intsll SOP\n Use this tool   C:\\Program Files\\ADLINK\\DEX-100\\utility\\BurnDex100_x64   Check the version that is C5 or C7\n  Upload the right bit\n  Note: The FPGA shall be null when you install the error bit.\n Cold boot    Utility_Manual Utility_Manual_20210426 (Download)\nHardware Hardware-Manual(Download)\n"
},
{
	"uri": "https://aiot-ist.github.io/mcm-204/gettingstart/",
	"title": "Getting Start",
	"tags": [],
	"description": "",
	"content": "This tutorial will guide you how to getting start with MCM-204 from un-boxing\nStep 1: Connect Power. Connect the positive and negative wires from a 9V to 30V DC power source to the terminal block. Step 2: Connect MCM-204 to PC or laptop. Connect MCM-204 to the PC or laptop by ethernet cable. Please make sure the PC/laptop network mode is under DHCP or static IP set at 169.254.x.x network segment.\n Step 3: Open the web browser to access the build-in web console. Open the web browser (chrome is recommanded) to access with the default IP http://169.254.1.1\nOnce acess MCM-204 web console sucessfully, the page will displayed like below. The default username is administrator and password is Adlink6166, after fill in these required information then click LOGIN to login to the web console. Step 4: Device Setting Click menu Device Setting to enter the device setting page. You could control the analog input setting and customize what kind of data you want to acquire. You could scroll the page to the bottom and simply click Apply to apply the default setting at this tutorial.\nAfter done, there will pop up a successful message to notify.\nStep 5: Data Capture Click menu Data Capture to enter the data display page and all the data set at last step will be displayed at this page.\nIf the data include the Voltage data type, you could click Draw to draw the voltage chart. "
},
{
	"uri": "https://aiot-ist.github.io/mcm-204/customalgorithm/",
	"title": "Custom Algorithm Deploy Sample",
	"tags": [],
	"description": "",
	"content": "This tutorial will guide you how to build your own algorithm and deploy to MCM-204 You could deploy your own algorithm at MCM-204.\nPrerequisites  Operating System : Ubuntu 18.04 installed and up-to date   Step 1: Download ARM gcc tool chain and examples. Please click below link to download zip file compressed of ARM gcc tool chain and examples at Ubuntu.\nDownload link: ARM tool chain with examples\nAfter downloaded, please extract it, then there will be a ARM tool chain folder and a sample folder called CalRMS.\nStep 2: Compile sample. Extract the downloaded file at Step 1.\n$ unzip CustomAlgorithm.zip Intall make, it\u0026rsquo;s not installed by default.\n$ sudo apt install make Change directory to the CalRMS\n$ cd CalRMS Build .so file from sample.\n$ make The customAlgo.so is build at current directory, you could use this file to upload to MCM-204.\n$ ls customAlgo.c customAlgo.h customAlgo.o customAlgo.so Makefile Step 3: Deploy the .so file to MCM-204 Once you completed above steps, you will get customAlgo.so. What we need to do next is deploy it to the MCM-204. Log in to MCM-204 web portal, if you don\u0026rsquo;t know how to login to web portal, you could click thie link to getting start page.\nAfter you login to web portal, then click System Setting menu. Scroll down to the bottom of page, then find the Customization library Upload section then click Choose File.\nAfter choose the customAlgo.so, simply click UPLOAD to upload it to the MCM-204 The upload process will finished at about 30 seconds, there will pop up a re login dialog until done. Simply click re-login link to re login to web portal. Step 4 Apply custom algorithm to device setting. Click Device Setting at MCM-204 web portal, then scroll down to Channel Config section At this tutorial we use the default setting of AI0, simply click ADD DATATYPE, then choose Data Type to Customization and input rms at Customization Parameter. Scroll down to the bottom of page then click Apply\n)\nStep 5 Display custom algorithm result. Click Data Capture and the data will be displayed at Customization key of returned JSON data. You could enter to next tutorial to learn how to develope your own algorithm.\n"
},
{
	"uri": "https://aiot-ist.github.io/mcm-204/customalgorithmdev/",
	"title": "Custom Algorithm Development",
	"tags": [],
	"description": "",
	"content": "This tutorial will guide you how to develop your own algorithm In the previous tutorial, we can get the RMS or Mean value through the sample code CustomAlgorithm.zip. This tutorial will modify the sample code to get the RMS and Mean value at the same time.\nPrerequisites  Operating System : Ubuntu 18.04 installed and up-to date   Step 1: Change the output data from 1 to 2. Find the following code from customAlgo.c.\ndouble* CustomAlgo(uint16_t chIndex, void *rawData, DeviceInfo devInfo, char* customParams, uint32_t* outCount) { uint32_t* raw = (uint32_t*)rawData; double inputRange = devInfo.inputRange == B10 ? 10.0 : 1.25; double scalingFactor = inputRange/8388607.0*1000.0/devInfo.sensor.sensitivity;//for convert rawData to g const uint32_t COUNT = 1; double* data = (double*)malloc(sizeof(double) * COUNT); double* gArray = (double*)malloc(sizeof(double) * devInfo.dataCount); raw = raw + chIndex*devInfo.dataCount; *outCount = COUNT; for(int i = 0; i \u0026lt; devInfo.dataCount; i++) gArray[i] = scalingFactor*(((raw[i] \u0026amp; 0x00800000) == 0x00800000) ? (int32_t)(raw[i] | 0xFF000000) : (int32_t)raw[i]); if(strcmp(customParams, \u0026quot;rms\u0026quot;)==0) data[0] = GetRms(gArray, devInfo.dataCount); else data[0] = GetMean(gArray, devInfo.dataCount); free(gArray); return data; } Modify COUNT to 2 in line 34.\nconst uint32_t COUNT = 2; Step 2: Change the output data. Modify conditions, then save and deploy the code.\nif(strcmp(customParams, \u0026quot;rms\u0026quot;)==0) { data[0] = GetRms(gArray, devInfo.dataCount); } else if(strcmp(customParams,\u0026quot;mean\u0026quot;)==0) { data[0] = GetMean(gArray, devInfo.dataCount); } else if(strcmp(customParams,\u0026quot;both\u0026quot;)==0) { data[0]=GetRms(gArray,devInfo.dataCount); data[1]=GetMean(gArray,devInfo.dataCount); } Step 3: Apply custom algorithm to device setting. Please refer to the previous tutorial.\nStep 4: Modify Customization Parameter. Enter both in customization parameter. Step 5: Display custom algorithm result. Click Data Capture and the data will be displayed at Customization key of returned JSON data. In this way you can get the RMS and the Mean value at the same time.\n"
},
{
	"uri": "https://aiot-ist.github.io/mcm-204/faq/",
	"title": "FAQ",
	"tags": [],
	"description": "",
	"content": "Frequently asked questions (FAQ) about MCM-204\nGeneral   What is the default IP address? The default IP is the fixed link local IP address 169.254.1.1  How to connect by hostname? The connection via hostname relies on DNS service, please make sure the DNS service is functional.   Programming   What kinds of API supported?   RESTFul API : You could get most everything via this.   C/C++ API : Used for getting rawdata more effiency.     "
},
{
	"uri": "https://aiot-ist.github.io/dex/",
	"title": "DEX",
	"tags": [],
	"description": "",
	"content": "ADLINK IST Connected Factory DEX-100 Discover how to use the DEX series and find the releated questions.\n"
},
{
	"uri": "https://aiot-ist.github.io/neon-2000-jt2/",
	"title": "NEON-2000-JT2",
	"tags": [],
	"description": "",
	"content": "ADLINK IST Connected Factory NEON-2000-JT2 Discover how to use the NEON-2000-JT2 and find the releated questions.\n"
},
{
	"uri": "https://aiot-ist.github.io/neon-2000-jt2/gettingstart/",
	"title": "Getting start",
	"tags": [],
	"description": "",
	"content": "This tutorial will guide you how to getting start with Neon-iSeries from un-boxing.\n Hardware wiring Inference by NEON Run DI/O Sample  Hardware wiring The NEON-2000-JT2 DC power source can be either from a USB Type-C adaptor or DC jack. The USB Type-C connector also supports a DisplayPort video signal and USB3, which can be used to connect a keyboard and mouse. The following figures show examples of possible power and peripheral connection configurations.\n Separate Power and Peripheral Connections  This configuration requires an ADLINK AC/DC power adapter (P/N 31-62156-1000-A0).    Combined Power and Peripheral Connections  This configuration requires an ADLINK USB Type-C hub/adapter (P/N 92-99090-1010).     Inference by NEON The inference sample, Capture_and_inference_Sample, is built on the Desktop of NEON-2000-JT2.\n  inference by image\n ./imagenet-console [input_image][output_image]  cd ~/Desktop/Capture_and_Inference_Sample/build/aarch64/bin ./imagenet-console ./aarch64/bin/jellyfish.jpg ./aarch64/bin/output.jpg   inference by camera\n ./imagenet-camera [input_width] [input_height]  cd ~/Desktop/Capture_and_Inference_Sample/build/aarch64/bin ./imagenet-camera 1920 1080     Run DIO Sample  Get hardware and DI/O information   cd /usr/src/Neon/Sample/Neon_Information sudo ./Neon_Information     Get hardware and DI/O information by python   cd /usr/src/Neon/Sample/Neon_Python sudo python Neon.py    "
},
{
	"uri": "https://aiot-ist.github.io/neon-2000-jnx/howtoflashimage/",
	"title": "How to flash image?",
	"tags": [],
	"description": "",
	"content": "It needs to go force recovery mode first before flash image. Here’s the video which guild you how to flash image.\nStep 1: Download image first from your host pc with Ubuntu Download link Neon-2000-JNX  Jetpack 4.5 v1.0.3   MicroSD image MD5:243b98f10a873f2830e4f635eab7c80d\n  MicroSD image with EVA_IDE sample MD5:8a5dfb448b49a50622b0a94b10a7fa2b\n  eMMC image MD5:e603db76e8ab1bbe5596760d40adb90c\n    Check sum  check md5 check sum to make sure image file is correct  Linux   $ md5sum [file]   $ md5sum JNX_JP45_microSD_v1.0.3.tar.gz    Windows 10   $ certutil -hashfile [file] MD5   $ certutil -hashfile JNX_JP45_microSD_v1.0.3.tar.gz MD5       Step 2: Follow video and flash microSD card image   unzip the image   $ tar -zxvf JNX_JP45_microSD_v1.0.3.tar.gz    Follow the video to flash image  Video of flash SOP    Step 3: Follow document and flash eMMC image  SOP of Flash eMMC  "
},
{
	"uri": "https://aiot-ist.github.io/neon-2000-jnx/",
	"title": "NEON-2000-JNX",
	"tags": [],
	"description": "",
	"content": "ADLINK IST Connected Factory NEON-2000-JNX Discover how to use the NEON-2000-JNX and find the releated questions.\n"
},
{
	"uri": "https://aiot-ist.github.io/neon-2000-jt2/howtobackupneonibymicrosd/",
	"title": "How to backup Neon by microSD card?",
	"tags": [],
	"description": "",
	"content": " Clone Neon data to microSD card Backup microSD card as image Recovery microSD card by image  According to the official document, the boot sequence is decided by U-boot. U-Boot functionality includes a default booting scan sequence. It scans bootable devices in the following order:\n External SD card Internal eMMC (Jetson TX2 series devices only) USB device (Jetson TX2 series devices only) NFS device  U-Boot boots up the kernel by /boot/extlinux/extlinux.conf in the sequence of bootable device. That is to say, if NEON-2000-JT2 equits microSD card with OS, U-Boot boots up accord to /boot/extlinux/extlinux.conf in microSD card instead of extlinux.conf in eMMC.\nRequirements:  32G up microSD card NEON-2000-JT2  Clone Neon data to microSD card Step 1: Format your microSD card as ext4 The total size of image with Jetpack4.4 is 16G. It suggests clone image by 32G microSD card.\n Insert microSD card in Neon  Right click on microSD card folder and click Format\u0026hellip;  Fill Volume Name:JP44 for example. Choose Type as Internal disk for use with Liunux ststems only (Ext4)  Confirm details and click Format  Search applications: Disks  Select SD Card Reader -\u0026gt; Mount selected partition   Step 2: Clone eMMC data to microSD   Make sure NEON-2000-JT2 mounts your microSD card /dev/mmcblk2p1.\ndf -h   Clone eMMC data to microSD\nsudo cp -ax / '/media/adlink/yourSDcard' \u0026amp;\u0026amp; sync   Step 3: Modify extlinux.conf in microSD card for bootup sequence   Edit /boot/extlinux/extlinux.conf in microSD card\n APPEND ${cbootargs} quiet\n  APPEND ${cbootargs} rootfstype=ext4 root=/dev/mmcblk2p1 rw rootwait\n   Step 4: Reboot NEON-2000-JT2  It will boot from microSD card.  Reference\nOptional Backup microSD card as image Step 1. Use command and check the disk of microSD in PC df -h Step 2. Image a card with dd if=path_of_your_image.img of=**/dev/disk**\nsudo dd bs=4M if=/dev/sdd status=progress | zip Neon-2000-JT2-JP43.zip - Recovery microSD card by image  image for microSD, Jetpack 4.3 v1.0.2 MD5: ae005ea9624999fb0922c487322680d1s  Step 1. Unzip the image unzip Neon-2000-JT2-JP43.zip Step 2. Rename it mv - unzip Neon-2000-JT2-JP43.image Step 3. Insert microSD and flash it by Etcher "
},
{
	"uri": "https://aiot-ist.github.io/neon-2000-jt2/howtouseneontocontroldio/",
	"title": "How to use NEON to control DI/O?",
	"tags": [],
	"description": "",
	"content": "Here is the list for our demo devices. Different devices might have different default settings. Please adjust the procedures based on your corresponding devices.\n Easy Intermediate  Easy Devices List:  ADLINK NEON-2000-JT2 ADLINK DIN-37D-01 Tend TPTL4 LED 24V Power Supply  Step 1. Connect the Neon with the din board through a connector. Step 2. Connect the LED\u0026rsquo;s negative wire in pin 4 for digital output (we take DO1 as an example). Step 3. Plug the 24V power supply\u0026rsquo;s negative wire in Din board\u0026rsquo;s pin 10 for grounding. Step 4. Coneect the positive of power supply with the positive of LED. Step 5. Use Neon to control the LED.\n Use the command cd /usr/src/Neon/Sample/Neon_Setting to adjust Neon setting. Use sudo ./Neon_Setting DO 1 1 to turn on the LED, use sudo ./Neon_Setting DO 1 0  to turn off the LED conversely.  Intermediate Devices List:  ADLINK NEON-1000-MDX ADLINK DIN-37D-01 High Bright Tech PC-24V24W-2-S 5V Power Supply  Step 1. Connect the light with the light controller at channel 1.\nStep 2. Connect the light controller with din board at strobe channel 1. Plug the positive wire in pin 3 for device output, and plug the negative wire in the pin 10 for grounding.\nStep 3. Connect the Neon with the din board through a connector.\nStep 4. Connect a trigger device on the din board. Insert the positive wire at pin 11 for trigger in, insert the negative wire at pin 10 for grounding. Here we used a 5V power supply for demonstration, you could connect your own device for your own purposes.\nStep 5. Adjust the default settings from Neon. Please enter the specific file path to adjust the settings. We modified the strobe-out polarity to set turning off the light as default, this step might be different due to your controller devices. Once the Neon reboots, the setting would be restored.\n Use command sudo -i to get in root mode.   Use the command cd /sys/class/neon_camctrl to change directory.   Use cat command to check current status. To change the default setting of strobe-out polarity, use the command echo 1 \u0026gt;StrobeOutPolarity.  Step 6. To extend or narrow the device strobe out time, please follow the steps\n Use the command cd /usr/src/Neon/Sample/Neon_Setting to change the current working directory.   To adjust the strobe out time, use the command sudo ./NeonSet StrobeOutPulseWidth N. The parameter N is the time of the width, the unit is us(10^-6 second).   For checking current infos of Neon, please change the directory with the command cd /usr/src/Neon/Sample/Neon_Information. Use sudo ./NeonInformation to get current status.  "
},
{
	"uri": "https://aiot-ist.github.io/neon-2000-jt2/howtoflashimage/",
	"title": "How to flash image?",
	"tags": [],
	"description": "",
	"content": "It needs to go force recovery mode first before flash image. Here’s the video which guild you how to flash image.\nStep 1: Download image first from your host pc with Ubuntu Download link Neon-2000-JT2  Jetpack 4.2.1 Jetpack 4.3 v1.0.0 Jetpack 4.3 v1.0.2 MD5:e70d52d564e09b11b76fa74314c96c79 Jetpack 4.4 v1.0.3 (MD5:19ee6e9bed2247d5894c3e9066d20b2b)   Link\n  Backup link2\n  microSD image MD5:9ccc55b9dec65b15eefee866e6a1fc85\n  MicroSD image with EVA_IDE sample MD5:8f7166c83e87f2ad67e182fe4e9c9d90\n    Neon-2000-JT2-X   Jetpack 4.3 v1.0.2 MD5:17e9d5c0b25505f22c472844051ea528\n  Jetpack 4.4 v1.0.2 (MD5:2592aa408fbcba2357fd94d623bfa7cb)\n  $ mv A2_Linux_for_Tegra.20200818.zip A2_Linux_for_Tegra.20200818.tbz2 $ tar -jxvf A2_Linux_for_Tegra.20200818.tbz2     Check sum  check md5 check sum to make sure image file is correct  Linux   $ md5sum [file]   $ md5sum JNX_JP45_microSD_v1.0.2.tar.gz    Windows 10   $ certutil -hashfile [file] MD5   $ certutil -hashfile JNX_JP45_microSD_v1.0.2.tar.gz MD5       Step 2: Follow video and flash image   Video link1\n  at NEON-2000-JT2/JNX\n Power on NEON-2000-JT2/JNX. Enter force recovery mode.    at Host PC\n Unzip the file downloading from Step 1  $ tar -zxvf Linux_for_Tegra_JetPack43.tar.gz or\n$ tar -jxvf A4_Linux_for_Tegra.20200528_JT2_JP43_v1.0.2.tbz2 You can refer to pin define below, and try to enter recover mode.   Step 1: Hold recovery btn (short pin5+pin6)\n  Step 2: Press reset btn (short pin3+pint4)\n  Go to flash folder\n  cd Linux_for_Tegra_JetPack43  Flash the Neon-2000-JT2  sudo ./flash.sh -r jetson-tx2 mmcblk0p1  Flash the Neon-2000-JNX  sudo ./flash.sh    Below video it the procedure for NEON-2000-JT2 flash   "
},
{
	"uri": "https://aiot-ist.github.io/neon-2000-jt2/howtochooselenses/",
	"title": "How to choose suitable lens for Neon?",
	"tags": [],
	"description": "",
	"content": "Here\u0026rsquo;s the lens selector tool from Basler website. Please enter your criteria and we\u0026rsquo;ll show you suitable lens models.\nStep 1: Select camera series and model Takes Neon-203B for example\nStep 2: Please enter as many values as possible. Missing values will be calculated automatically. Take example for real case:\n At 75ft(22860 mm) needs to support a field of view that is 406 inches (10312 mm) X 406 inches (10312 mm) And supports a 10ft depth of field  Step 3: Display suitable lenses If you want to use the lens with a CS-mount camera, a distance ring (5 mm) must be attached to the lens.\nStep 4: You can contact with your vendor and find the similar spec of lenses. Kindly remind you that the smaller focal length may cause “fisheye” effect.\nThe document from Basler website explains what you should know when selecting a lens for your camera.\n"
},
{
	"uri": "https://aiot-ist.github.io/neon-2000-jt2/faq/",
	"title": "FAQ",
	"tags": [],
	"description": "",
	"content": "Frequently asked questions (FAQ) about NEON-2000-JT2\n Model and Sensor Specifications Hardware Specifications Software Specificationonment Software Version check  General   NEON-2000-JT2 Model and Sensor Specifications      Model Name Image Sensor Specification Image Sensor Module     NEON-201B-JT2 1/ 3\u0026rdquo;, 1.2M, Global Shutter , 1280x 960, 54fps, COLOR Basler, DAA1280-54UC-CS   NEON-202B-JT2 1/1.8\u0026rdquo;, 1.9M, Global Shutter , 1600x1200, 60fps, COLOR Basler, DAA1600-60UC-CS   NEON-203B-JT2 1/3.7\u0026rdquo;, 2 M, Rolling Shutter, 1920x1080, 30fps, COLOR Basler, DAA1920-30UC-CS   NEON-204B-JT2 1/2.5\u0026rdquo;, 5 M, Rolling Shutter, 2592x1944, 14fps, COLOR Basler, DAA2500-14UC-CS      Hardware Specification      Neon-iSeries Digital Input Digital Output UART Dimensions Weight     Neon-iSeries 4x DI, includes 1x sensor trigger 4x DO, includes 1x strobe out TXD, RXD, GND 123.3 x 66.81 x 77.5 mm 700g      Software environment      Neon-iSeries JetPack L4T Ubuntu CUDA cuDNN TensorRT Python2 Python3 Pylon     Version 4.2.1 32.2 18.04.2LTS 10.0 7.5.0.56 5.1.6.1 2.7.15 3.6.9 5.0.9   Version 4.3 32.3.1 18.04.2LTS 10.0.326 7.6.3.28 6.0.1.10 2.7.17 3.6.9 5.2.0   Version 4.4 32.4.3 18.04.2LTS 10.2.89 8.0.0.180 7.1.3.0 2.7.17 3.6.9 5.2.0      Version check   TensorRT dpkg -l|grep nvinfer   CUDA nvcc --version   cuDNN dpkg -l|grep cudnn   Python python --version     "
},
{
	"uri": "https://aiot-ist.github.io/neon-1000-mdx/",
	"title": "Neon-1000-MDX",
	"tags": [],
	"description": "",
	"content": "ADLINK IST Connected Factory Neon-1000-MDX Discover how to use the Neon-1000-MDX and find the releated questions.\n"
},
{
	"uri": "https://aiot-ist.github.io/news/",
	"title": "News",
	"tags": [],
	"description": "",
	"content": "News of ADLINK-IST Connected Factory "
},
{
	"uri": "https://aiot-ist.github.io/news/mcm/",
	"title": "MCM",
	"tags": [],
	"description": "",
	"content": "News of MCM series "
},
{
	"uri": "https://aiot-ist.github.io/news/mcm/20200310/",
	"title": "簡化管理成本 一站式遠端即時監控成設備業者新利器",
	"tags": [],
	"description": "",
	"content": "  凌華科技產品經理林耿賢指出，凌華遠端監控解決方案的架構完整、功能強大，可為設備供應商創造出全新的商業模式。DIGITIMES攝     工業4.0所帶來的所帶來的智慧化革命，不僅改變了傳統的生產概念，也衝擊了製造業的營運思維，在物聯網、AI、大數據等技術的落地應用下，設備供應商除了單純的產品買賣外，還可將原有的服務加值，進而延展出以服務為導向的商業模式，不過凌華科技產品經理林耿賢指出，要提供這類型商業模式，需要完整的配套方案，在客戶意願未確定前就投入研發，對設備供應商是沉重的負擔，凌華科技近期針對泵浦、壓縮機等設備推出的遠端監控解決方案，則以高完整性特色，提供設備供應商快速打造系統，創造另一波商機。\n穩定度是生產設備的基本要求，尤其是泵浦、壓縮機這類對產線運作有關鍵影響的設備，一但無預警故障，整條產線就會因此停擺，為了避免此一狀況發生，製造業者與設備供應商在商定採購合約時，都會加入定期保養服務條款，而且即便保固到期後，製造業者通常也願意付費維持此服務，確保產線穩定運作。\n  遠端即時監控系統是完整的工業物聯網機制，從終端到雲端都必須完整建置，系統功能才能一如預期的發揮。   定期保養維修雖可大幅提升設備的穩定度，但仍無法完全排除臨時故障的機率，這幾年興起的工業物聯網概念，則可透過感測網路、大數據與AI等技術在線即時偵測設備，並進一步分析可能故障的時間，讓管理者可從遠端掌握設備狀態，從而排定維修時程，讓產線稼動率最大化。\n林耿賢也指出，遠端即時監控系統是完整的工業物聯網機制，從終端到雲端都必須完整建置，系統功能才能一如預期的發揮，然而系統的設計與打造需要高度專業，多數設備供應商並未具備相關技能，因此即便新服務可帶來新商機，資源有限的業者仍無力掌握。\n除此之外，設備業者如果能快速打造遠端即時監控系統，將有機會創造更多商業模式，因此業者凌華針對泵浦、壓縮機等旋轉設備提供一站式整體解決方案，此一方案從最前端感測器到上層的雲端平台一應俱全，且系統穩定度極高，更特別的是在凌華團隊的設計下，此系統大幅簡化導入程序，設備供應商可在短期內完成建置，讓系統快速上線使用。\n林耿賢說明此一解決方案之終端設備採用凌華專為設備監控設計的MCM-204嵌入式邊緣裝置，其小巧精簡的機構設計可快速安裝於製造場域，縮短系統布建導入時間。此外整合ARM處理器和DAQ功能模組的優化設計，完美實現一站式傳感器數據採集、數據分析和數據上傳的邊緣運算能力和優勢，用戶不需再額外配置物聯網網關，節省建置成本。\n在感測器部份，可支援ICP Type壓電式加速規感測器進行設備振動數據，或數位溫度傳感器和轉速計可量測設備溫度和轉速。至於雲端平台部分，則是基於微軟Azure所打造的SaaS –DataConnect Pro\n功能完整、簡單易用、快速上線的特色，讓凌華的一站式遠端監控解決方案，成為設備供應商開拓新商機的最有力幫手。林耿賢指出，透過此一解決方案，設備供應商可擁有三大優勢。首先是強化客戶關係，業者可在既有的產品買賣服務上增加差異化服務，維持企業營收。其次是擴大服務層面，創造出全新的商業模式，例如以年租型的收費方式提供機台監控服務，將以往的定期保養服務進階為在線即時監控維修服務，讓製造業者為自己的機台多買一份保險。最後則是提升維修效能，在全面且即時掌握設備狀態下，業者可彈性安排維修時程，零組件備貨也可更精準，有效活化企業資產。\n隨著智慧化概念的普及，製造設備供應商的市場定位已開始改變，單純的產品銷售與維修服務將難以因應製造業客戶的需求，能夠提供多元、到位服務的業者，才能在競爭日益激烈的產業環境中站穩腳步，而在專業分工的如今，善用外部力量強化自身競爭力，將會是企業營運的最佳策略，凌華的遠端監控解決方案就可讓設備供應商以有限的資源提升效能、擴展商業模式，並為客戶與自身企業創造出更多元的價值。\n"
},
{
	"uri": "https://aiot-ist.github.io/news/mcm/20200311/",
	"title": "迎接轉型挑戰 金屬加工業者瞄準布局AI設備管理",
	"tags": [],
	"description": "",
	"content": "  固德科技技術經理許文澤指出，設備狀態監測可大幅提升製造產線效能。DIGITIMES攝    沖壓、焊接是金屬加工中常見的製程動作，在此製程中，設備運作的狀態對產線效能與品質有關鍵影響，像是設備狀態有誤卻仍持續動作，或是設備無故障預警停機，前者會產生大量廢料，後者則是導致產線停擺，這都會造成企業的大量損失，為解決此問題，固德科技以機器學習演算法結合凌華的邊緣推論設備MCM-100，打造出智慧化產線設備狀態監測平台，讓各類型金屬加工業者可透過AI與工業物聯網架構即時掌握產線設備，強化生產效能。\n固德科技技術經理許文澤指出，金屬加工的產線設備多元，依設備動作可分為連續性與非連續性兩種，連續性是指馬達之類隨時處於運轉狀態的設備，非連續性則是像大型機器手臂、沖壓床或自動焊接等設備，無論是連續性或非連續性，這些生產設備都是製造業者最重要的生財工具，一但出錯就會帶來龐大損失。\n  固德科技VMS-ML機器學習系統可進行沖壓、衝孔製程的即時監測。   許文澤以汽車製造為例，沖壓是汽車零組件常見的製程，在此製程中，模具品質異常將會影響沖壓出的產品品質，而這往往要到後端品保環節才會被檢出，但在檢出之前，產線上已然出現大量不合格的產品，此一問題影響所及者不只是金錢，還包括產線停機確認、改善與生產工時增加等時間問題，這些問題不僅出現在汽車製造，小至螺絲、大至航太產業用的金屬件，只要使用到金屬加工的產品都會遇到。\n為了解決此一問題，現在市場上已出現各種設備狀態智慧監診系統，這類型系統都是透過工業物聯網的感測網路與AI，偵測並分析設備狀態，在設備故障前先行警告管理人員，避免上述問題產生，而其中AI的機器學習演算法更是其中關鍵。許文澤指出在金屬加工中，非連續性製程都可透過感測器偵測其動作狀態，像是沖壓的震動、焊接的電流變化都有其模式，在現在製程中，這些模式都是由機台操作人員依靠長期經驗所累積，而在智慧製造體系中，就是將人的經驗轉值給機器學習演算法，當震動或電流模式與之不符，就會警告管理人員。\nAI的機器學習演算法需要大量數據進行訓練，因此現在市場上多數採用機器學習演算法的設備監診系統，都必須先建置感測器收集數據，等待設備出現異常再註記標籤紀錄，讓機器學習從中認知訓練，然而這種方式曠日廢時，製造業者需要耗費大量成本收集數據，因此並非最佳選擇。固德科技的做法則可讓系統可即時上線使用，許文澤表示，固德科技會先在終端先預載經過訓練的震動或電流模型，省去製造業者收集數據的時間，接著再由平台快速學習製造業者指定的數據範圍。學習完成的系統具備了自動追蹤與辨識功能，每一個設備運作的狀態都會被記錄，同時回饋給管理者，管理者可自行調整、決定設備運作。\n固德科技的設備狀態監測系統的上線即用設計中，凌華的MCM-100扮演了關鍵角色。許文澤指出，過去設備監控系統所用的終端設備，都必須由廠商分別購置工業電腦與擷取卡，組裝後再不斷測試，調整出符合需求的架構，這不但會延長系統開發時程，也增加了工程師的工作負擔，MCM-100的出現則解決了這些問題。MCM-100是凌華專為智慧製造所設計的即用型旋轉機械設備振動／狀態監測平台，其特色是具備高效能邊緣運算能力，內建的四通道有24位元、128kS/s同步擷取類比輸入，可同時偵測多感測器所傳回的訊號，多元而豐富的I/O介面也大幅提升其整合性。在MCM-100的高整合與強大效能支援下，固德科技可專注於系統開發，讓在短時間內上線使用。\n許文澤最後表示，智慧化是製造業近年來最重要的趨勢，而設備監測現已被多數業者視為導入智慧製造系統的第一步，不過對製造業說，智慧化仍是全新概念，系統的導入與調整往往需要耗費大量成本，固德科技與凌華合作打造的AI設備監測平台，透過高整合、高效能的軟硬體整合，可讓系統快速導入使用，大幅降低系統上線的成本，提早享受智慧製造所帶來的效益，順利跨出數位轉型的第一步。\n"
},
{
	"uri": "https://aiot-ist.github.io/",
	"title": "ADLINK-IST Connected Factories",
	"tags": [],
	"description": "",
	"content": "ADLINK-IST Connected Factory Discover the sharing of technical documents and the common questions. You could navigate from the menu or simply type the keyword to search!\n "
},
{
	"uri": "https://aiot-ist.github.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "https://aiot-ist.github.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]